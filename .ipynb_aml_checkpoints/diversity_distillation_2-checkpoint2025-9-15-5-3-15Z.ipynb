{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22340cd8-8215-43fe-abd0-10a6d99e85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.enable_grad(False)\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "from utils.load_util import load_sdxl_models, load_pipe\n",
    "\n",
    "\n",
    "\n",
    "distillation_type='turbo' # what type of distillation model do you want to use (\"dmd\", \"lcm\", \"turbo\", \"lightning\")\n",
    "device = 'mps'\n",
    "weights_dtype = torch.bfloat16\n",
    "\n",
    "pipe, base_unet, base_scheduler, distilled_unet, distilled_scheduler = load_sdxl_models(distillation_type=distillation_type, \n",
    "                                                                                        weights_dtype=weights_dtype, \n",
    "                                                                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259d32e-38a4-4a31-b5d5-ee65dbed9847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_distillation(prompt, seed, pipe, base_unet, distilled_unet, distilled_scheduler, base_guidance_scale=5, distilled_guidance_scale=0, num_inference_steps=4, run_base_till=1):\n",
    "    pipe.scheduler = distilled_scheduler\n",
    "    pipe.unet=base_unet\n",
    "\n",
    "    base_latents = pipe(prompt,\n",
    "                    guidance_scale=base_guidance_scale,\n",
    "                    till_timestep=run_base_till, \n",
    "                    num_inference_steps=num_inference_steps,\n",
    "                    generator=torch.Generator().manual_seed(seed),\n",
    "                    output_type='latent'\n",
    "                   )\n",
    "    \n",
    "\n",
    "    pipe.unet = distilled_unet\n",
    "    images = pipe(prompt,\n",
    "                 guidance_scale=distilled_guidance_scale,\n",
    "                 start_latents = base_latents,   \n",
    "                 num_inference_steps=num_inference_steps,\n",
    "                 from_timestep=run_base_till,\n",
    "                 output_type='pil'\n",
    "                )\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3248e58-7e15-4f1b-8d3b-95fbfcfc9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'cartoon character'\n",
    "seed = random.randint(0, 2**15)\n",
    "\n",
    "images = diversity_distillation(prompt, seed, pipe, base_unet, distilled_unet, distilled_scheduler)\n",
    "\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67317047-2b14-42c8-863b-c6d9a4bf96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to generate images using only the distilled model\n",
    "def distilled_only_generation(prompt, seed, pipe, distilled_unet, distilled_scheduler, guidance_scale=0, num_inference_steps=4):\n",
    "    pipe.scheduler = distilled_scheduler\n",
    "    pipe.unet = distilled_unet\n",
    "    \n",
    "    images = pipe(prompt,\n",
    "                 guidance_scale=guidance_scale,\n",
    "                 num_inference_steps=num_inference_steps,\n",
    "                 generator=torch.Generator().manual_seed(seed),\n",
    "                 output_type='pil'\n",
    "                )\n",
    "    return images\n",
    "\n",
    "# Function to generate images using only the base model\n",
    "def base_only_generation(prompt, seed, pipe, base_unet, base_scheduler, guidance_scale=5, num_inference_steps=20):\n",
    "    pipe.scheduler = base_scheduler\n",
    "    pipe.unet = base_unet\n",
    "    \n",
    "    images = pipe(prompt,\n",
    "                 guidance_scale=guidance_scale,\n",
    "                 num_inference_steps=num_inference_steps,\n",
    "                 generator=torch.Generator().manual_seed(seed),\n",
    "                 output_type='pil'\n",
    "                )\n",
    "    return images\n",
    "\n",
    "# User prompt\n",
    "prompt = \"car skidding to a stop\"  # Replace with your desired prompt\n",
    "num_images = 6  # 2x3 grid\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"generated_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "\n",
    "# Initialize variables\n",
    "total_time_diversity = 0\n",
    "total_time_distilled = 0\n",
    "total_time_base = 0\n",
    "all_diversity_images = []\n",
    "all_distilled_images = []\n",
    "all_base_images = []\n",
    "\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "\n",
    "# Generate images with all three methods\n",
    "for i in tqdm(range(num_images)):\n",
    "    # Generate random seed (use same seed for all methods for fair comparison)\n",
    "    seed = np.random.randint(0, 2**32 - 1)\n",
    "    \n",
    "    # Generate diversity distillation image\n",
    "    start_time = time.perf_counter()\n",
    "    diversity_image = diversity_distillation(prompt, seed, pipe, base_unet, distilled_unet, distilled_scheduler)[0]\n",
    "    end_time = time.perf_counter()\n",
    "    runtime_diversity = end_time - start_time\n",
    "    total_time_diversity += runtime_diversity\n",
    "    \n",
    "    # Generate distilled-only image\n",
    "    start_time = time.perf_counter()\n",
    "    distilled_image = distilled_only_generation(prompt, seed, pipe, distilled_unet, distilled_scheduler)[0]\n",
    "    end_time = time.perf_counter()\n",
    "    runtime_distilled = end_time - start_time\n",
    "    total_time_distilled += runtime_distilled\n",
    "    \n",
    "    # Generate base-only image\n",
    "    start_time = time.perf_counter()\n",
    "    base_image = base_only_generation(prompt, seed, pipe, base_unet, base_scheduler)[0]\n",
    "    end_time = time.perf_counter()\n",
    "    runtime_base = end_time - start_time\n",
    "    total_time_base += runtime_base\n",
    "    \n",
    "    # Save individual images to disk\n",
    "    diversity_filename = f\"{output_dir}/diversity_image_{i+1:02d}_seed_{seed}.png\"\n",
    "    distilled_filename = f\"{output_dir}/distilled_image_{i+1:02d}_seed_{seed}.png\"\n",
    "    base_filename = f\"{output_dir}/base_image_{i+1:02d}_seed_{seed}.png\"\n",
    "    diversity_image.save(diversity_filename)\n",
    "    distilled_image.save(distilled_filename)\n",
    "    base_image.save(base_filename)\n",
    "    \n",
    "    # Append to lists for grid creation\n",
    "    all_diversity_images.append(diversity_image)\n",
    "    all_distilled_images.append(distilled_image)\n",
    "    all_base_images.append(base_image)\n",
    "\n",
    "# Create comparison figure with three subplots side by side\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(ncols*9, nrows*3), dpi=200)\n",
    "\n",
    "# Create grid for diversity distillation images\n",
    "ax1.set_title(\"Diversity Distillation\\n(Base + Distilled)\", fontsize=14, pad=20)\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        idx = i * ncols + j\n",
    "        if idx < len(all_diversity_images):\n",
    "            # Calculate position for each image in the grid\n",
    "            y_start = (nrows - 1 - i) / nrows\n",
    "            y_end = (nrows - i) / nrows\n",
    "            x_start = j / ncols\n",
    "            x_end = (j + 1) / ncols\n",
    "            \n",
    "            # Create inset axes for each image\n",
    "            img_ax = ax1.inset_axes([x_start, y_start, x_end - x_start, y_end - y_start])\n",
    "            img_ax.imshow(all_diversity_images[idx])\n",
    "            img_ax.axis('off')\n",
    "\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.axis('off')\n",
    "\n",
    "# Create grid for distilled-only images\n",
    "ax2.set_title(\"Distilled Model Only\\n(4 steps)\", fontsize=14, pad=20)\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        idx = i * ncols + j\n",
    "        if idx < len(all_distilled_images):\n",
    "            # Calculate position for each image in the grid\n",
    "            y_start = (nrows - 1 - i) / nrows\n",
    "            y_end = (nrows - i) / nrows\n",
    "            x_start = j / ncols\n",
    "            x_end = (j + 1) / ncols\n",
    "            \n",
    "            # Create inset axes for each image\n",
    "            img_ax = ax2.inset_axes([x_start, y_start, x_end - x_start, y_end - y_start])\n",
    "            img_ax.imshow(all_distilled_images[idx])\n",
    "            img_ax.axis('off')\n",
    "\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.axis('off')\n",
    "\n",
    "# Create grid for base-only images\n",
    "ax3.set_title(\"Base Model Only\\n(20 steps)\", fontsize=14, pad=20)\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        idx = i * ncols + j\n",
    "        if idx < len(all_base_images):\n",
    "            # Calculate position for each image in the grid\n",
    "            y_start = (nrows - 1 - i) / nrows\n",
    "            y_end = (nrows - i) / nrows\n",
    "            x_start = j / ncols\n",
    "            x_end = (j + 1) / ncols\n",
    "            \n",
    "            # Create inset axes for each image\n",
    "            img_ax = ax3.inset_axes([x_start, y_start, x_end - x_start, y_end - y_start])\n",
    "            img_ax.imshow(all_base_images[idx])\n",
    "            img_ax.axis('off')\n",
    "\n",
    "ax3.set_xlim(0, 1)\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print timing information\n",
    "print(f\"Diversity Distillation - Total Runtime: {total_time_diversity:.4f} seconds\")\n",
    "print(f\"Diversity Distillation - Average per image: {total_time_diversity/num_images:.4f} seconds\")\n",
    "print(f\"Distilled Only - Total Runtime: {total_time_distilled:.4f} seconds\")\n",
    "print(f\"Distilled Only - Average per image: {total_time_distilled/num_images:.4f} seconds\")\n",
    "print(f\"Base Only - Total Runtime: {total_time_base:.4f} seconds\")\n",
    "print(f\"Base Only - Average per image: {total_time_base/num_images:.4f} seconds\")\n",
    "print(f\"Individual images saved to: {output_dir}/\")\n",
    "\n",
    "# Save the comparison grid\n",
    "comparison_filename = f\"{output_dir}/three_way_comparison_{prompt.replace(' ', '_')}.png\"\n",
    "plt.savefig(comparison_filename, bbox_inches='tight', pad_inches=0.1, dpi=200)\n",
    "print(f\"Three-way comparison grid saved to: {comparison_filename}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258477f-e104-4547-ad5a-98b778b13563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
