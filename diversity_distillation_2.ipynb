{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22340cd8-8215-43fe-abd0-10a6d99e85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.enable_grad(False)\n",
    "\n",
    "# Enable PyTorch performance optimizations\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "from utils.load_util import load_sdxl_models, load_pipe\n",
    "\n",
    "\n",
    "\n",
    "distillation_type='dmd'  # what type of distillation model do you want to use (\"dmd\", \"lcm\", \"turbo\", \"lightning\")\n",
    "device = 'cuda:0'  # Use CUDA for A100 GPU\n",
    "weights_dtype = torch.bfloat16  # Use bfloat16 for better performance on A100\n",
    "\n",
    "pipe, base_unet, base_scheduler, distilled_unet, distilled_scheduler = load_sdxl_models(distillation_type=distillation_type, \n",
    "                                                                                        weights_dtype=weights_dtype, \n",
    "                                                                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259d32e-38a4-4a31-b5d5-ee65dbed9847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_distillation(prompt, seed, pipe, base_unet, distilled_unet, distilled_scheduler, base_guidance_scale=5, distilled_guidance_scale=0, num_inference_steps=4, run_base_till=1):\n",
    "    pipe.scheduler = distilled_scheduler\n",
    "    pipe.unet=base_unet\n",
    "\n",
    "    base_latents = pipe(prompt,\n",
    "                    guidance_scale=base_guidance_scale,\n",
    "                    till_timestep=run_base_till, \n",
    "                    num_inference_steps=num_inference_steps,\n",
    "                    generator=torch.Generator().manual_seed(seed),\n",
    "                    output_type='latent'\n",
    "                   )\n",
    "    \n",
    "\n",
    "    pipe.unet = distilled_unet\n",
    "    images = pipe(prompt,\n",
    "                 guidance_scale=distilled_guidance_scale,\n",
    "                 start_latents = base_latents,   \n",
    "                 num_inference_steps=num_inference_steps,\n",
    "                 from_timestep=run_base_till,\n",
    "                 output_type='pil'\n",
    "                )\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3248e58-7e15-4f1b-8d3b-95fbfcfc9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'cartoon character'\n",
    "seed = random.randint(0, 2**15)\n",
    "\n",
    "images = diversity_distillation(prompt, seed, pipe, base_unet, distilled_unet, distilled_scheduler)\n",
    "\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67317047-2b14-42c8-863b-c6d9a4bf96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to generate images using only the distilled model\n",
    "def distilled_only_generation(prompt, seed, pipe, distilled_unet, distilled_scheduler, guidance_scale=0, num_inference_steps=4):\n",
    "    pipe.scheduler = distilled_scheduler\n",
    "    pipe.unet = distilled_unet\n",
    "    \n",
    "    images = pipe(prompt,\n",
    "                 guidance_scale=guidance_scale,\n",
    "                 num_inference_steps=num_inference_steps,\n",
    "                 generator=torch.Generator().manual_seed(seed),\n",
    "                 output_type='pil'\n",
    "                )\n",
    "    return images\n",
    "\n",
    "# Function to generate images using only the base model\n",
    "def base_only_generation(prompt, seed, pipe, base_unet, base_scheduler, guidance_scale=5, num_inference_steps=20):\n",
    "    pipe.scheduler = base_scheduler\n",
    "    pipe.unet = base_unet\n",
    "    \n",
    "    images = pipe(prompt,\n",
    "                 guidance_scale=guidance_scale,\n",
    "                 num_inference_steps=num_inference_steps,\n",
    "                 generator=torch.Generator().manual_seed(seed),\n",
    "                 output_type='pil'\n",
    "                )\n",
    "    return images\n",
    "\n",
    "# User prompt\n",
    "prompt = \"bear in a top hat\"  # Replace with your desired prompt\n",
    "num_images = 6  # 2x3 grid\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"generated_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "\n",
    "# Initialize variables\n",
    "total_time_diversity = 0\n",
    "total_time_distilled = 0\n",
    "total_time_base = 0\n",
    "all_diversity_images = []\n",
    "all_distilled_images = []\n",
    "all_base_images = []\n",
    "\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "\n",
    "# Generate images with all three methods\n",
    "for i in tqdm(range(num_images)):\n",
    "    # Generate random seed (use same seed for all methods for fair comparison)\n",
    "    seed = np.random.randint(0, 2**32 - 1)\n",
    "    \n",
    "    # Generate diversity distillation image\n",
    "    start_time = time.perf_counter()\n",
    "    diversity_image = diversity_distillation(prompt, seed, pipe, base_unet, distilled_unet, distilled_scheduler)[0]\n",
    "    end_time = time.perf_counter()\n",
    "    runtime_diversity = end_time - start_time\n",
    "    total_time_diversity += runtime_diversity\n",
    "    \n",
    "    # Generate distilled-only image\n",
    "    start_time = time.perf_counter()\n",
    "    distilled_image = distilled_only_generation(prompt, seed, pipe, distilled_unet, distilled_scheduler)[0]\n",
    "    end_time = time.perf_counter()\n",
    "    runtime_distilled = end_time - start_time\n",
    "    total_time_distilled += runtime_distilled\n",
    "    \n",
    "    # Generate base-only image\n",
    "    start_time = time.perf_counter()\n",
    "    base_image = base_only_generation(prompt, seed, pipe, base_unet, base_scheduler)[0]\n",
    "    end_time = time.perf_counter()\n",
    "    runtime_base = end_time - start_time\n",
    "    total_time_base += runtime_base\n",
    "    \n",
    "    # Save individual images to disk\n",
    "    diversity_filename = f\"{output_dir}/diversity_image_{i+1:02d}_seed_{seed}.png\"\n",
    "    distilled_filename = f\"{output_dir}/distilled_image_{i+1:02d}_seed_{seed}.png\"\n",
    "    base_filename = f\"{output_dir}/base_image_{i+1:02d}_seed_{seed}.png\"\n",
    "    diversity_image.save(diversity_filename)\n",
    "    distilled_image.save(distilled_filename)\n",
    "    base_image.save(base_filename)\n",
    "    \n",
    "    # Append to lists for grid creation\n",
    "    all_diversity_images.append(diversity_image)\n",
    "    all_distilled_images.append(distilled_image)\n",
    "    all_base_images.append(base_image)\n",
    "\n",
    "# Create comparison figure with three subplots side by side\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(ncols*9, nrows*3), dpi=200)\n",
    "\n",
    "# Create grid for diversity distillation images\n",
    "ax1.set_title(\"Diversity Distillation\\n(Base + Distilled)\", fontsize=14, pad=20)\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        idx = i * ncols + j\n",
    "        if idx < len(all_diversity_images):\n",
    "            # Calculate position for each image in the grid\n",
    "            y_start = (nrows - 1 - i) / nrows\n",
    "            y_end = (nrows - i) / nrows\n",
    "            x_start = j / ncols\n",
    "            x_end = (j + 1) / ncols\n",
    "            \n",
    "            # Create inset axes for each image\n",
    "            img_ax = ax1.inset_axes([x_start, y_start, x_end - x_start, y_end - y_start])\n",
    "            img_ax.imshow(all_diversity_images[idx])\n",
    "            img_ax.axis('off')\n",
    "\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.axis('off')\n",
    "\n",
    "# Create grid for distilled-only images\n",
    "ax2.set_title(\"Distilled Model Only\\n(4 steps)\", fontsize=14, pad=20)\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        idx = i * ncols + j\n",
    "        if idx < len(all_distilled_images):\n",
    "            # Calculate position for each image in the grid\n",
    "            y_start = (nrows - 1 - i) / nrows\n",
    "            y_end = (nrows - i) / nrows\n",
    "            x_start = j / ncols\n",
    "            x_end = (j + 1) / ncols\n",
    "            \n",
    "            # Create inset axes for each image\n",
    "            img_ax = ax2.inset_axes([x_start, y_start, x_end - x_start, y_end - y_start])\n",
    "            img_ax.imshow(all_distilled_images[idx])\n",
    "            img_ax.axis('off')\n",
    "\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.axis('off')\n",
    "\n",
    "# Create grid for base-only images\n",
    "ax3.set_title(\"Base Model Only\\n(20 steps)\", fontsize=14, pad=20)\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        idx = i * ncols + j\n",
    "        if idx < len(all_base_images):\n",
    "            # Calculate position for each image in the grid\n",
    "            y_start = (nrows - 1 - i) / nrows\n",
    "            y_end = (nrows - i) / nrows\n",
    "            x_start = j / ncols\n",
    "            x_end = (j + 1) / ncols\n",
    "            \n",
    "            # Create inset axes for each image\n",
    "            img_ax = ax3.inset_axes([x_start, y_start, x_end - x_start, y_end - y_start])\n",
    "            img_ax.imshow(all_base_images[idx])\n",
    "            img_ax.axis('off')\n",
    "\n",
    "ax3.set_xlim(0, 1)\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print timing information\n",
    "print(f\"Diversity Distillation - Total Runtime: {total_time_diversity:.4f} seconds\")\n",
    "print(f\"Diversity Distillation - Average per image: {total_time_diversity/num_images:.4f} seconds\")\n",
    "print(f\"Distilled Only - Total Runtime: {total_time_distilled:.4f} seconds\")\n",
    "print(f\"Distilled Only - Average per image: {total_time_distilled/num_images:.4f} seconds\")\n",
    "print(f\"Base Only - Total Runtime: {total_time_base:.4f} seconds\")\n",
    "print(f\"Base Only - Average per image: {total_time_base/num_images:.4f} seconds\")\n",
    "print(f\"Individual images saved to: {output_dir}/\")\n",
    "\n",
    "# Save the comparison grid\n",
    "comparison_filename = f\"{output_dir}/three_way_comparison_{prompt.replace(' ', '_')}.png\"\n",
    "plt.savefig(comparison_filename, bbox_inches='tight', pad_inches=0.1, dpi=200)\n",
    "print(f\"Three-way comparison grid saved to: {comparison_filename}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5324aa",
   "metadata": {},
   "source": [
    "# Multi-Model Diversity Comparison\n",
    "\n",
    "Compare diversity across three different distillation models: DMD, Lightning, and Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configuration\n",
    "prompt = \"frog in a hat\"\n",
    "num_images = 6  # 2x3 grid\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "\n",
    "# Models to compare\n",
    "model_types = ['dmd', 'lightning', 'turbo']\n",
    "model_names = {\n",
    "    'dmd': 'DMD',\n",
    "    'lightning': 'Lightning', \n",
    "    'turbo': 'Turbo'\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"multi_model_comparison\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Store results for each model and method\n",
    "all_results = {}\n",
    "timing_results = {}\n",
    "\n",
    "print(f\"Comparing 3 generation methods across {len(model_types)} models: {', '.join(model_names.values())}\")\n",
    "print(f\"Generating {num_images} images per method per model with prompt: '{prompt}'\\n\")\n",
    "\n",
    "# Load and test each model\n",
    "for model_type in model_types:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Loading {model_names[model_type]} model...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load the model\n",
    "    start_load = time.time()\n",
    "    model_pipe, model_base_unet, model_base_scheduler, model_distilled_unet, model_distilled_scheduler = load_sdxl_models(\n",
    "        distillation_type=model_type,\n",
    "        weights_dtype=torch.bfloat16,\n",
    "        device=device\n",
    "    )\n",
    "    load_time = time.time() - start_load\n",
    "    print(f\"✓ {model_names[model_type]} loaded in {load_time:.2f}s\")\n",
    "    \n",
    "    # Initialize storage for this model\n",
    "    all_results[model_type] = {\n",
    "        'diversity': [],\n",
    "        'distilled': [],\n",
    "        'base': []\n",
    "    }\n",
    "    timing_results[model_type] = {\n",
    "        'diversity': {'total': 0, 'average': 0},\n",
    "        'distilled': {'total': 0, 'average': 0},\n",
    "        'base': {'total': 0, 'average': 0},\n",
    "        'load_time': load_time\n",
    "    }\n",
    "    \n",
    "    model_pipe.set_progress_bar_config(disable=True)\n",
    "    \n",
    "    # Generate images with all three methods\n",
    "    for i in tqdm(range(num_images), desc=f\"Generating {model_names[model_type]} images\"):\n",
    "        # Use same seed for all methods for fair comparison\n",
    "        seed = np.random.randint(0, 2**32 - 1)\n",
    "        \n",
    "        # 1. Diversity Distillation (Base + Distilled)\n",
    "        start_time = time.perf_counter()\n",
    "        diversity_images = diversity_distillation(\n",
    "            prompt, seed, model_pipe, \n",
    "            model_base_unet, model_distilled_unet, \n",
    "            model_distilled_scheduler\n",
    "        )\n",
    "        gen_time = time.perf_counter() - start_time\n",
    "        timing_results[model_type]['diversity']['total'] += gen_time\n",
    "        all_results[model_type]['diversity'].append(diversity_images[0])\n",
    "        \n",
    "        # Save individual image\n",
    "        diversity_filename = f\"{output_dir}/{model_type}_diversity_{i+1:02d}_seed_{seed}.png\"\n",
    "        diversity_images[0].save(diversity_filename)\n",
    "        \n",
    "        # 2. Distilled Model Only\n",
    "        start_time = time.perf_counter()\n",
    "        distilled_images = distilled_only_generation(\n",
    "            prompt, seed, model_pipe,\n",
    "            model_distilled_unet, model_distilled_scheduler\n",
    "        )\n",
    "        gen_time = time.perf_counter() - start_time\n",
    "        timing_results[model_type]['distilled']['total'] += gen_time\n",
    "        all_results[model_type]['distilled'].append(distilled_images[0])\n",
    "        \n",
    "        # Save individual image\n",
    "        distilled_filename = f\"{output_dir}/{model_type}_distilled_{i+1:02d}_seed_{seed}.png\"\n",
    "        distilled_images[0].save(distilled_filename)\n",
    "        \n",
    "        # 3. Base Model Only\n",
    "        start_time = time.perf_counter()\n",
    "        base_images = base_only_generation(\n",
    "            prompt, seed, model_pipe,\n",
    "            model_base_unet, model_base_scheduler\n",
    "        )\n",
    "        gen_time = time.perf_counter() - start_time\n",
    "        timing_results[model_type]['base']['total'] += gen_time\n",
    "        all_results[model_type]['base'].append(base_images[0])\n",
    "        \n",
    "        # Save individual image\n",
    "        base_filename = f\"{output_dir}/{model_type}_base_{i+1:02d}_seed_{seed}.png\"\n",
    "        base_images[0].save(base_filename)\n",
    "    \n",
    "    # Calculate averages\n",
    "    for method in ['diversity', 'distilled', 'base']:\n",
    "        timing_results[model_type][method]['average'] = timing_results[model_type][method]['total'] / num_images\n",
    "    \n",
    "    print(f\"✓ Generated {num_images*3} images total ({num_images} per method)\")\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del model_pipe, model_base_unet, model_base_scheduler, model_distilled_unet, model_distilled_scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Creating comparison visualization...\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Create comparison figure: 3 rows (methods) x 3 columns (models)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(ncols*10, nrows*11), dpi=200)\n",
    "\n",
    "method_labels = {\n",
    "    'diversity': 'Diversity Distillation\\n(Base + Distilled)',\n",
    "    'distilled': 'Distilled Model Only\\n(4 steps)',\n",
    "    'base': 'Base Model Only\\n(20 steps)'\n",
    "}\n",
    "methods = ['diversity', 'distilled', 'base']\n",
    "\n",
    "# Create grid for each combination of method and model\n",
    "for method_idx, method in enumerate(methods):\n",
    "    for model_idx, model_type in enumerate(model_types):\n",
    "        ax = axes[method_idx, model_idx]\n",
    "        model_name = model_names[model_type]\n",
    "        avg_time = timing_results[model_type][method]['average']\n",
    "        \n",
    "        # Title includes model name, method, and timing\n",
    "        if method_idx == 0:  # Top row gets model name\n",
    "            title = f\"{model_name}\\n{method_labels[method]}\\n{avg_time:.2f}s/img\"\n",
    "        else:\n",
    "            title = f\"{method_labels[method]}\\n{avg_time:.2f}s/img\"\n",
    "        \n",
    "        ax.set_title(title, fontsize=12, pad=15, fontweight='bold')\n",
    "        \n",
    "        # Create grid for this method's images\n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                idx = i * ncols + j\n",
    "                if idx < len(all_results[model_type][method]):\n",
    "                    # Calculate position for each image in the grid\n",
    "                    y_start = (nrows - 1 - i) / nrows\n",
    "                    y_end = (nrows - i) / nrows\n",
    "                    x_start = j / ncols\n",
    "                    x_end = (j + 1) / ncols\n",
    "                    \n",
    "                    # Create inset axes for each image\n",
    "                    img_ax = ax.inset_axes([x_start, y_start, x_end - x_start, y_end - y_start])\n",
    "                    img_ax.imshow(all_results[model_type][method][idx])\n",
    "                    img_ax.axis('off')\n",
    "        \n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print comprehensive timing information\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TIMING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "for model_type in model_types:\n",
    "    model_name = model_names[model_type]\n",
    "    results = timing_results[model_type]\n",
    "    print(f\"\\n{model_name} (Load time: {results['load_time']:.2f}s):\")\n",
    "    print(f\"  Diversity Distillation:\")\n",
    "    print(f\"    Total: {results['diversity']['total']:.2f}s | Avg: {results['diversity']['average']:.2f}s | Throughput: {1.0/results['diversity']['average']:.2f} img/s\")\n",
    "    print(f\"  Distilled Only:\")\n",
    "    print(f\"    Total: {results['distilled']['total']:.2f}s | Avg: {results['distilled']['average']:.2f}s | Throughput: {1.0/results['distilled']['average']:.2f} img/s\")\n",
    "    print(f\"  Base Only:\")\n",
    "    print(f\"    Total: {results['base']['total']:.2f}s | Avg: {results['base']['average']:.2f}s | Throughput: {1.0/results['base']['average']:.2f} img/s\")\n",
    "\n",
    "print(f\"\\nIndividual images saved to: {output_dir}/\")\n",
    "\n",
    "# Save the comparison grid\n",
    "comparison_filename = f\"{output_dir}/full_comparison_{prompt.replace(' ', '_')}.png\"\n",
    "plt.savefig(comparison_filename, bbox_inches='tight', pad_inches=0.1, dpi=200)\n",
    "print(f\"Full comparison grid saved to: {comparison_filename}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Multi-model multi-method comparison complete!\")\n",
    "print(f\"Total images generated: {len(model_types) * 3 * num_images} ({len(model_types)} models × 3 methods × {num_images} images)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Diversity Distillation)",
   "language": "python",
   "name": "diversity-distillation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
